{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d671c6e5",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "- Human Brain works with biological neurone. Ability of machine to recognize things like digits, obj on its own is known as neural network.\n",
    "- Multiple neurons are combined to form a neural network.\n",
    "\n",
    "## Anatomy of Neural Network\n",
    "- There are three layers :\n",
    "1. Input layer --> It takes pixels from images\n",
    "2. Hidden layer --> Doing computations and extracting features. \n",
    "3. Output layer --> Provides prediction (i.e 0-9)\n",
    "\n",
    "- Key Concepts\n",
    "1. Weight(w): Learnable parameters controlling input importance.\n",
    "2. Bias(b):  shift the activation function curve.\n",
    "3. Activation Function :  Change to non linearity (eg. ReLU, Sigmoid, tanh , etc.)\n",
    "4. Loss Function:  Measures how wrong our model is \n",
    "5. Optimizers:  Adjust the weight to minimize loss (SGD,Adam,etc)\n",
    "\n",
    "- Math behind Neural Network:\n",
    "- x(i) --> Input\n",
    "- w(i) --> weight\n",
    "- b --> Bias\n",
    "- z --> weighted sum\n",
    "\n",
    "  - z = w1x1+w2x2+......+wnxn +b \n",
    "\n",
    "  - Activation Function \n",
    "     a = f(z)\n",
    "\n",
    "     - If you use ReLU \n",
    "     f(z)= max(0,z)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa45bcb",
   "metadata": {},
   "source": [
    "# Classification of digit using Neural Network\n",
    "\n",
    "# MNIST(Modified National Institue of Standards and Technology) : \n",
    "- 70K images datas for handwritten digits (0-9)\n",
    "- This is the hello world of computer vision\n",
    "- 28*28 size images grayscales pixel \n",
    "- Train = 60k\n",
    "- Test = 10k "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93422713",
   "metadata": {},
   "source": [
    "# Preprossing MNIST dataset \n",
    "- Before Feeding the Neural Network\n",
    "- Flatten 28*28 : 784 input features (for dense layer) or keep as 28*28 is we are using CNN\n",
    "- Normalization : Divide value into 255 to get in range [0,1]\n",
    "- One-hot Encoding : For eg [0 0 0 1 0 0 0 0 0 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d667ab2",
   "metadata": {},
   "source": [
    "# MNIST dataset training testing and evaluation \n",
    "# neural network architecture\n",
    " - Input : 784 neurons\n",
    " - hidden layer: 128 neurons(ReLU)\n",
    " - hidden layer : 64 neurons(ReLU)\n",
    " - output layer : 10 neurons (0-9)\n",
    "\n",
    " # for training \n",
    " 1. Invalid weight randomly \n",
    " 2. Forward pass: Compute predicition\n",
    " 3. Calculate loss: \n",
    "  - Summation(yilog(yicap))\n",
    " 4. Backpropagation error\n",
    " 5. Updated weight \n",
    " 6. Repeate it for many epochs until convergnaces\n",
    "\n",
    "\n",
    " # Challenges\n",
    " 1. Overfitting : Model memorizes training data but fails with new images data\n",
    "       - Dropout , regularization\n",
    " 2. Underfitting : Model too simple (lesss datasets)\n",
    " 3. Learning rate tuning: \n",
    "    - too high : model unstable\n",
    "    - too low : slow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c126910",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"c:\\Users\\Alisha Bhusal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 73, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Alisha Bhusal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:73\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 73\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pywrap_tensorflow_internal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Externally in opensource we must enable exceptions to load the shared object\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# by exposing the PyInit symbols with pybind. This error will only be\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# This logic is used in other internal projects using py_extension.\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m \n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mnist \n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "File \u001b[1;32mc:\\Users\\Alisha Bhusal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\__init__.py:40\u001b[0m\n\u001b[0;32m     37\u001b[0m _os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mENABLE_RUNTIME_UPTIME_TELEMETRY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n",
      "File \u001b[1;32mc:\\Users\\Alisha Bhusal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:88\u001b[0m\n\u001b[0;32m     86\u001b[0m     sys\u001b[38;5;241m.\u001b[39msetdlopenflags(_default_dlopen_flags)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m---> 88\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     89\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraceback\u001b[38;5;241m.\u001b[39mformat_exc()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     90\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFailed to load the native TensorFlow runtime.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     91\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee https://www.tensorflow.org/install/errors \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     92\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfor some common causes and solutions.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     93\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you need help, create an issue \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     94\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mat https://github.com/tensorflow/tensorflow/issues \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     95\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mand include the entire stack trace above this error message.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"c:\\Users\\Alisha Bhusal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 73, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist \n",
    "from tensorflow.keras.model import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0f7e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset and visualize it \n",
    "(x_train,y_train ), (x_test,y_test)=mnist.load_data()\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "#digit \n",
    "plt.imshow(x_train[0], cmap='gray')\n",
    "plt.title(f\"Digit: (y_train{0})\")\n",
    "\n",
    "# to display multiple datas in row \n",
    "plt.figure(figsize=(100,20))\n",
    "\n",
    "for i in range(20):\n",
    "    plt.subplot(1,20,i+1)\n",
    "    plt.imshow(x_train[i],cmap='gray')\n",
    "    plt.titile(f\"digit : {y_train{i}}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b12b342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data preprocessing\n",
    "\n",
    "#Normalization \n",
    "x_train=x_train/255\n",
    "x_test=x_test/255\n",
    "\n",
    "\n",
    "#onhot encoding\n",
    "y_train_cat = to_categorical(y_train,10)\n",
    "y_test_cat = to_categorical(y_test,10)\n",
    "print(y_train_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8feb16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a feed forward neural network \n",
    "model= Sequential([\n",
    "    #flatten layer  2 shape convert it into 784(1D)\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    #first hidden layer \n",
    "    Dense(128,activation='relu'),\n",
    "    #second hidden layer \n",
    "    Dense(64,activation='relu'),\n",
    "    #output layer\n",
    "    Dense(10,activation='softmax'),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54d8d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model \"categorical crossover\"\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9454e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model\n",
    "history=model.fit(\n",
    "    x_train,\n",
    "    y_train_cat,\n",
    "    epos= 10, #no of passes over entire training datas\n",
    "    batch_size= 128,\n",
    "    validation_split=0.1 #10% of data remain for validation\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210207e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation \n",
    "loss,accuracy = model.evaluate (x_test,y_test_cat)\n",
    "print(f\"Test accuracy {accuracy} and loss value: {loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747a977a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the model\n",
    "plt.plot(history.history['accuracy'],label=\"Train accuracy curve\")\n",
    "plt.plot(history.history['val_accuracy'],label=\"Value Accuracy curve\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "plt.title(\"Training VS validation curve\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb27eae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict and visualize\n",
    "prediction = model.predict(x_test)\n",
    "for i in range(5):\n",
    "    plt.imshow(x_test[i],cmap='grey')\n",
    "    plt.title(f\"Actual : {y_test[i]}| predict: {prediction[i]}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccca419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "model.save(\"mnist_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37803423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b6fdf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58ae0bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fd7da5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6157de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
