{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d53367d",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "Human brain works with biological nurone. Ability of machine to recognize things like digits, obj on its own is known as neural network.\n",
    "Multiple neurons are combined to form a neural network\n",
    "\n",
    "## Anatomy of Neural Network\n",
    "\n",
    "There are three layers:\n",
    "1. Input layer -->It takes pixels as input from images.\n",
    "2. Hidden layer --> Doing computation and extracting features\n",
    "3. Output layer --> Provides prediction(i.e. 0.9)\n",
    "\n",
    "Key Concepts:\n",
    "1. weight(w): Learnable parameters controlling input importance\n",
    "2. Bias (b): Shift the activation function curve \n",
    "3. Activation Function : Change to non-Linearlity(ReLu, Sigmoid, Tanh)\n",
    "4. Loss Function: Measures how wrong our model\n",
    "5. Optimizers: Adjust the weight to minimize loss(SGD, Adam, etc)\n",
    "\n",
    "- Math behind Neural Network:\n",
    "- x(i) -->input \n",
    "- w(i) --> weight \n",
    "- b --> bias\n",
    "- z --> Weighted Sum\n",
    "\n",
    "    z= w1x1+w2x2+....................wnxn+b\n",
    "\n",
    "- Activation Function:\n",
    "a=f(z)\n",
    "\n",
    "- If we use ReLU\n",
    "f(z) = max(0,z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84abcd2d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e068cdf8",
   "metadata": {},
   "source": [
    "#Classification of digits using NN:\n",
    "\n",
    "#MNIST (Modified National Institute of Standards and Technology)\n",
    "#This is hello world of computer vision\n",
    "\n",
    "- 70K images datas for handwritten digits(0,9)\n",
    "- 28*28 size images grayscale pixel.\n",
    "- Train = 60k\n",
    "- Test = 10K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c560a7",
   "metadata": {},
   "source": [
    "#Preprocessing MNIST dataset\n",
    "- Before feeding the neural network\n",
    "- Flattern 28 * 28 = 784 input features (for dense layer) or keep as 28*28 is we are using CNN.\n",
    "- Normalization : Divide the value by 255 to get in range [0,1]\n",
    "- One-hot Encoding : for eg [0 0 0 1 0 0 0 0 0 0] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f60788",
   "metadata": {},
   "source": [
    "#MNIST dataset Training Testing and Evaluation\n",
    "# \n",
    "# #Neural Network Architecture\n",
    "- Input : 784 neurones\n",
    "- Hidden layer : 128 neurones (ReLU)\n",
    "- Hidden layer : 64 neurones (ReLU)\n",
    "- Output layer : 10 neurones (0-9)\n",
    "\n",
    "#For training. \n",
    "1. Initialize weight randomly\n",
    "2. Forward pass : Compute prediction \n",
    "3. Calculate loss :\n",
    "    - Summation (y(log(yicap)))\n",
    "4. Backpropagation error\n",
    "5. Updated Weight \n",
    "6. Repeat it for many epochs until convergances "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26678c46",
   "metadata": {},
   "source": [
    "#Challenges:\n",
    "\n",
    "1. Overfittng :\n",
    "    Model memorizes training data but fails with new images data.\n",
    "        Dropout, regularization, \n",
    "2. Underfitting :\n",
    "    Model too simple(from datasets)\n",
    "3. Learning rate tuning:\n",
    "    - too hight = unstable\n",
    "    - too low = slow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0fed54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf \n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Flatten\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c385a3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset and visualize it\n",
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    " \n",
    "# Digit\n",
    "for i in range(20):\n",
    "    plt.subplot(1,20,i+1)\n",
    "    plt.imshow(x_train[i], cmap='gray')\n",
    "    plt.title(f\"Digit:{y_train[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d73b684",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    # Flatten Layer\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "\n",
    "    # First Hidden layer\n",
    "    Dense(128, activation='relu'),\n",
    "\n",
    "    # Second Hidden layer\n",
    "    Dense(64, activation='relu'),\n",
    "\n",
    "    # Output layer\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0b61cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the  model \n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21315d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,y_train cat,\n",
    "    epochs =10, #no of passes over the entire training datas\n",
    "    batch_size =120,\n",
    "    validation_split = 0.1 #10% of data remaining validation \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8e123b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation\n",
    "loss,accuracy= model.evaluate(x_test,y_test_cat)\n",
    "print(f\"Test accuracy { accuracy} and loss value {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa13291b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the model \n",
    "plt.plot(history.history['accuracy'], label=\"Training Accuracy Curve\")\n",
    "plt.plot(history.history['val_accuracy'],label=\"value accutracy form\")\n",
    "plt.xlabel(\"Epos\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"Trainig  Vs validation curve\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d5c635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict and Visualized\n",
    "prediction=model.predict(x_test)\n",
    "for i in range(5):\n",
    "    plt.imshow(x_test[i],cmap='gray')\n",
    "    plt.title(f\"Actual :{y_test[i]} | predict:{prediction[i]}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1232f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "model.save(\"mnist_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6142ce41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
